---
type: lecture
date: 2022-09-06
title: (dl4cv-9) Training DNNs-II

# optional
# please use /static_files/notes directory to store notes
# thumbnail: /static_files/path/to/image.jpg 

# optional
tldr: "Some more important aspects of training deep neural networks."
  
# optional
# set it to true if you dont want this lecture to appear in the updates section
hide_from_announcments: false

# optional
links: 
    - url: /static_files/sgd_update_rules.gif
      name: sgd_update_rules.gif
    - url: https://colab.research.google.com/drive/1__iXdKpepXortelx06I35RYfnu94Dg4t?usp=sharing
      name: Codes-Update rules implementation
    - url: /static_files/presentations/dl4cv-9.pdf
      name: slides
    #- url: /static_files/presentations/lec.zip
    #  name: other
---
**Suggested Readings:**
- [Optimization update rules by Sebastian Ruder](https://ruder.io/optimizing-gradient-descent/)
- [SGD with Momentum, I Sutskever et al. ICML 2013](https://proceedings.mlr.press/v28/sutskever13.html)
- [Ada Grad, Duchi et al. JMLR, 2011](https://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf)
- [Adam, Kingma et al. ICLR 2015](https://arxiv.org/abs/1412.6980)
- [Some insgihts about lr in dl](https://towardsdatascience.com/understanding-learning-rates-and-how-it-improves-performance-in-deep-learning-d0d4059c1c10)
- [Random search for hyper-parameter selection, Bergstra, JMLR 2012](https://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf)
